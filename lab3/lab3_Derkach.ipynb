{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPsHrlueCiJN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.io.arff import loadarff \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "nOf_9CvqDOBX",
        "outputId": "8d19d4b7-3736-4d74-ab96-bd39be6e8164"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
              "0       74923.0   1101.567       385.532964       248.443048      1.551796   \n",
              "1       33752.0    685.368       258.843071       166.339893      1.556109   \n",
              "2       36824.0    689.547       236.361416       198.577267      1.190274   \n",
              "3       52808.0    928.664       332.582478       202.732146      1.640502   \n",
              "4       47124.0    810.080       301.736291       199.665053      1.511212   \n",
              "...         ...        ...              ...              ...           ...   \n",
              "13606   40166.0    731.962       252.627058       202.940053      1.244836   \n",
              "13607   35315.0    682.216       240.633701       187.269379      1.284960   \n",
              "13608   43460.0    773.873       276.821080       201.064006      1.376781   \n",
              "13609  207561.0   1752.359       667.531421       400.332038      1.667444   \n",
              "13610   73806.0   1033.627       392.508898       240.175051      1.634262   \n",
              "\n",
              "       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
              "0          0.764676     76197.0     308.860691  0.774254  0.983280   0.775895   \n",
              "1          0.766178     34150.0     207.302632  0.759137  0.988346   0.902946   \n",
              "2          0.542366     37125.0     216.531229  0.767199  0.991892   0.973225   \n",
              "3          0.792733     54100.0     259.301434  0.702683  0.976118   0.769471   \n",
              "4          0.749751     47631.0     244.949261  0.766506  0.989356   0.902394   \n",
              "...             ...         ...            ...       ...       ...        ...   \n",
              "13606      0.595549     40541.0     226.143626  0.753866  0.990750   0.942088   \n",
              "13607      0.627974     35619.0     212.048236  0.777692  0.991465   0.953510   \n",
              "13608      0.687344     44108.0     235.233906  0.788090  0.985309   0.911927   \n",
              "13609      0.800210    210438.0     514.076719  0.720660  0.986329   0.849395   \n",
              "13610      0.790937     74622.0     306.549699  0.691391  0.989065   0.868108   \n",
              "\n",
              "       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n",
              "0         0.801127      0.005146      0.001307      0.641804      0.995949   \n",
              "1         0.800882      0.007669      0.001946      0.641411      0.998106   \n",
              "2         0.916102      0.006419      0.002789      0.839243      0.998930   \n",
              "3         0.779661      0.006298      0.001435      0.607871      0.997213   \n",
              "4         0.811799      0.006403      0.001715      0.659018      0.995916   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "13606     0.895168      0.006290      0.002491      0.801326      0.997519   \n",
              "13607     0.881208      0.006814      0.002534      0.776527      0.997806   \n",
              "13608     0.849769      0.006370      0.002049      0.722107      0.994183   \n",
              "13609     0.770116      0.003216      0.000698      0.593079      0.988926   \n",
              "13610     0.781001      0.005318      0.001221      0.609962      0.996838   \n",
              "\n",
              "       Class  \n",
              "0          1  \n",
              "1          6  \n",
              "2          0  \n",
              "3          1  \n",
              "4          5  \n",
              "...      ...  \n",
              "13606      0  \n",
              "13607      6  \n",
              "13608      5  \n",
              "13609      2  \n",
              "13610      1  \n",
              "\n",
              "[13611 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2de281b7-1fd0-4d06-96d0-d8d7a89881ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Perimeter</th>\n",
              "      <th>MajorAxisLength</th>\n",
              "      <th>MinorAxisLength</th>\n",
              "      <th>AspectRation</th>\n",
              "      <th>Eccentricity</th>\n",
              "      <th>ConvexArea</th>\n",
              "      <th>EquivDiameter</th>\n",
              "      <th>Extent</th>\n",
              "      <th>Solidity</th>\n",
              "      <th>roundness</th>\n",
              "      <th>Compactness</th>\n",
              "      <th>ShapeFactor1</th>\n",
              "      <th>ShapeFactor2</th>\n",
              "      <th>ShapeFactor3</th>\n",
              "      <th>ShapeFactor4</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>74923.0</td>\n",
              "      <td>1101.567</td>\n",
              "      <td>385.532964</td>\n",
              "      <td>248.443048</td>\n",
              "      <td>1.551796</td>\n",
              "      <td>0.764676</td>\n",
              "      <td>76197.0</td>\n",
              "      <td>308.860691</td>\n",
              "      <td>0.774254</td>\n",
              "      <td>0.983280</td>\n",
              "      <td>0.775895</td>\n",
              "      <td>0.801127</td>\n",
              "      <td>0.005146</td>\n",
              "      <td>0.001307</td>\n",
              "      <td>0.641804</td>\n",
              "      <td>0.995949</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33752.0</td>\n",
              "      <td>685.368</td>\n",
              "      <td>258.843071</td>\n",
              "      <td>166.339893</td>\n",
              "      <td>1.556109</td>\n",
              "      <td>0.766178</td>\n",
              "      <td>34150.0</td>\n",
              "      <td>207.302632</td>\n",
              "      <td>0.759137</td>\n",
              "      <td>0.988346</td>\n",
              "      <td>0.902946</td>\n",
              "      <td>0.800882</td>\n",
              "      <td>0.007669</td>\n",
              "      <td>0.001946</td>\n",
              "      <td>0.641411</td>\n",
              "      <td>0.998106</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36824.0</td>\n",
              "      <td>689.547</td>\n",
              "      <td>236.361416</td>\n",
              "      <td>198.577267</td>\n",
              "      <td>1.190274</td>\n",
              "      <td>0.542366</td>\n",
              "      <td>37125.0</td>\n",
              "      <td>216.531229</td>\n",
              "      <td>0.767199</td>\n",
              "      <td>0.991892</td>\n",
              "      <td>0.973225</td>\n",
              "      <td>0.916102</td>\n",
              "      <td>0.006419</td>\n",
              "      <td>0.002789</td>\n",
              "      <td>0.839243</td>\n",
              "      <td>0.998930</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>52808.0</td>\n",
              "      <td>928.664</td>\n",
              "      <td>332.582478</td>\n",
              "      <td>202.732146</td>\n",
              "      <td>1.640502</td>\n",
              "      <td>0.792733</td>\n",
              "      <td>54100.0</td>\n",
              "      <td>259.301434</td>\n",
              "      <td>0.702683</td>\n",
              "      <td>0.976118</td>\n",
              "      <td>0.769471</td>\n",
              "      <td>0.779661</td>\n",
              "      <td>0.006298</td>\n",
              "      <td>0.001435</td>\n",
              "      <td>0.607871</td>\n",
              "      <td>0.997213</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>47124.0</td>\n",
              "      <td>810.080</td>\n",
              "      <td>301.736291</td>\n",
              "      <td>199.665053</td>\n",
              "      <td>1.511212</td>\n",
              "      <td>0.749751</td>\n",
              "      <td>47631.0</td>\n",
              "      <td>244.949261</td>\n",
              "      <td>0.766506</td>\n",
              "      <td>0.989356</td>\n",
              "      <td>0.902394</td>\n",
              "      <td>0.811799</td>\n",
              "      <td>0.006403</td>\n",
              "      <td>0.001715</td>\n",
              "      <td>0.659018</td>\n",
              "      <td>0.995916</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13606</th>\n",
              "      <td>40166.0</td>\n",
              "      <td>731.962</td>\n",
              "      <td>252.627058</td>\n",
              "      <td>202.940053</td>\n",
              "      <td>1.244836</td>\n",
              "      <td>0.595549</td>\n",
              "      <td>40541.0</td>\n",
              "      <td>226.143626</td>\n",
              "      <td>0.753866</td>\n",
              "      <td>0.990750</td>\n",
              "      <td>0.942088</td>\n",
              "      <td>0.895168</td>\n",
              "      <td>0.006290</td>\n",
              "      <td>0.002491</td>\n",
              "      <td>0.801326</td>\n",
              "      <td>0.997519</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13607</th>\n",
              "      <td>35315.0</td>\n",
              "      <td>682.216</td>\n",
              "      <td>240.633701</td>\n",
              "      <td>187.269379</td>\n",
              "      <td>1.284960</td>\n",
              "      <td>0.627974</td>\n",
              "      <td>35619.0</td>\n",
              "      <td>212.048236</td>\n",
              "      <td>0.777692</td>\n",
              "      <td>0.991465</td>\n",
              "      <td>0.953510</td>\n",
              "      <td>0.881208</td>\n",
              "      <td>0.006814</td>\n",
              "      <td>0.002534</td>\n",
              "      <td>0.776527</td>\n",
              "      <td>0.997806</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13608</th>\n",
              "      <td>43460.0</td>\n",
              "      <td>773.873</td>\n",
              "      <td>276.821080</td>\n",
              "      <td>201.064006</td>\n",
              "      <td>1.376781</td>\n",
              "      <td>0.687344</td>\n",
              "      <td>44108.0</td>\n",
              "      <td>235.233906</td>\n",
              "      <td>0.788090</td>\n",
              "      <td>0.985309</td>\n",
              "      <td>0.911927</td>\n",
              "      <td>0.849769</td>\n",
              "      <td>0.006370</td>\n",
              "      <td>0.002049</td>\n",
              "      <td>0.722107</td>\n",
              "      <td>0.994183</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13609</th>\n",
              "      <td>207561.0</td>\n",
              "      <td>1752.359</td>\n",
              "      <td>667.531421</td>\n",
              "      <td>400.332038</td>\n",
              "      <td>1.667444</td>\n",
              "      <td>0.800210</td>\n",
              "      <td>210438.0</td>\n",
              "      <td>514.076719</td>\n",
              "      <td>0.720660</td>\n",
              "      <td>0.986329</td>\n",
              "      <td>0.849395</td>\n",
              "      <td>0.770116</td>\n",
              "      <td>0.003216</td>\n",
              "      <td>0.000698</td>\n",
              "      <td>0.593079</td>\n",
              "      <td>0.988926</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13610</th>\n",
              "      <td>73806.0</td>\n",
              "      <td>1033.627</td>\n",
              "      <td>392.508898</td>\n",
              "      <td>240.175051</td>\n",
              "      <td>1.634262</td>\n",
              "      <td>0.790937</td>\n",
              "      <td>74622.0</td>\n",
              "      <td>306.549699</td>\n",
              "      <td>0.691391</td>\n",
              "      <td>0.989065</td>\n",
              "      <td>0.868108</td>\n",
              "      <td>0.781001</td>\n",
              "      <td>0.005318</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.609962</td>\n",
              "      <td>0.996838</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13611 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2de281b7-1fd0-4d06-96d0-d8d7a89881ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2de281b7-1fd0-4d06-96d0-d8d7a89881ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2de281b7-1fd0-4d06-96d0-d8d7a89881ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "raw_data = loadarff('Dry_Bean_Dataset.arff')\n",
        "df = pd.DataFrame(raw_data[0])\n",
        "\n",
        "df.Class = pd.factorize(df.Class)[0]\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mW6Rw-3LIAsu"
      },
      "outputs": [],
      "source": [
        "y = df['Class']\n",
        "x = df.drop('Class',axis=1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state = 1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "y_train = to_categorical(y_train, 7)\n",
        "y_test = to_categorical(y_test, 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SVpyuCCaB8tf",
        "outputId": "09efc88c-686c-4f06-f569-5551870f192e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 1.4809 - accuracy: 0.5243 - val_loss: 1.0320 - val_accuracy: 0.7029\n",
            "Epoch 2/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.8728 - accuracy: 0.7663 - val_loss: 0.7482 - val_accuracy: 0.8147\n",
            "Epoch 3/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.8273 - val_loss: 0.6093 - val_accuracy: 0.8602\n",
            "Epoch 4/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.8576 - val_loss: 0.5236 - val_accuracy: 0.8827\n",
            "Epoch 5/10\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.8755 - val_loss: 0.4638 - val_accuracy: 0.8969\n",
            "Epoch 6/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.8873 - val_loss: 0.4204 - val_accuracy: 0.9030\n",
            "Epoch 7/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8907 - val_loss: 0.3870 - val_accuracy: 0.9084\n",
            "Epoch 8/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8958 - val_loss: 0.3610 - val_accuracy: 0.9084\n",
            "Epoch 9/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8991 - val_loss: 0.3400 - val_accuracy: 0.9134\n",
            "Epoch 10/10\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.9016 - val_loss: 0.3231 - val_accuracy: 0.9145\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.3403 - accuracy: 0.9053\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.9034\n",
            "Epoch 1/10\n",
            "146/146 [==============================] - 1s 5ms/step - loss: 1.1586 - accuracy: 0.6133 - val_loss: 0.7376 - val_accuracy: 0.7379\n",
            "Epoch 2/10\n",
            "146/146 [==============================] - 1s 3ms/step - loss: 0.5859 - accuracy: 0.8211 - val_loss: 0.4679 - val_accuracy: 0.8777\n",
            "Epoch 3/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.8858 - val_loss: 0.3406 - val_accuracy: 0.9041\n",
            "Epoch 4/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9021 - val_loss: 0.2811 - val_accuracy: 0.9161\n",
            "Epoch 5/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2789 - accuracy: 0.9112 - val_loss: 0.2535 - val_accuracy: 0.9128\n",
            "Epoch 6/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2557 - accuracy: 0.9141 - val_loss: 0.2336 - val_accuracy: 0.9172\n",
            "Epoch 7/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2421 - accuracy: 0.9180 - val_loss: 0.2247 - val_accuracy: 0.9161\n",
            "Epoch 8/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 0.9202 - val_loss: 0.2217 - val_accuracy: 0.9123\n",
            "Epoch 9/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.9206 - val_loss: 0.2104 - val_accuracy: 0.9211\n",
            "Epoch 10/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2232 - accuracy: 0.9212 - val_loss: 0.2076 - val_accuracy: 0.9194\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.2171 - accuracy: 0.9216\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9214\n",
            "Epoch 1/10\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 1.3606 - accuracy: 0.5242 - val_loss: 1.0448 - val_accuracy: 0.6645\n",
            "Epoch 2/10\n",
            "146/146 [==============================] - 1s 3ms/step - loss: 0.9093 - accuracy: 0.7157 - val_loss: 0.7916 - val_accuracy: 0.7758\n",
            "Epoch 3/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.7196 - accuracy: 0.8038 - val_loss: 0.6395 - val_accuracy: 0.8438\n",
            "Epoch 4/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.8570 - val_loss: 0.5386 - val_accuracy: 0.8854\n",
            "Epoch 5/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.8785 - val_loss: 0.4684 - val_accuracy: 0.9008\n",
            "Epoch 6/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.8928 - val_loss: 0.4178 - val_accuracy: 0.9052\n",
            "Epoch 7/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8992 - val_loss: 0.3807 - val_accuracy: 0.9057\n",
            "Epoch 8/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.9049 - val_loss: 0.3524 - val_accuracy: 0.9106\n",
            "Epoch 9/10\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.9079 - val_loss: 0.3302 - val_accuracy: 0.9117\n",
            "Epoch 10/10\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.9086 - val_loss: 0.3125 - val_accuracy: 0.9150\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.3267 - accuracy: 0.9113\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.9110\n",
            "Epoch 1/10\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 1.3613 - accuracy: 0.5073 - val_loss: 0.7860 - val_accuracy: 0.7637\n",
            "Epoch 2/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.8269 - val_loss: 0.4682 - val_accuracy: 0.8854\n",
            "Epoch 3/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8862 - val_loss: 0.3480 - val_accuracy: 0.9106\n",
            "Epoch 4/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.9053 - val_loss: 0.2886 - val_accuracy: 0.9172\n",
            "Epoch 5/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 0.9109 - val_loss: 0.2542 - val_accuracy: 0.9216\n",
            "Epoch 6/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.9171 - val_loss: 0.2365 - val_accuracy: 0.9216\n",
            "Epoch 7/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.9182 - val_loss: 0.2235 - val_accuracy: 0.9211\n",
            "Epoch 8/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2353 - accuracy: 0.9209 - val_loss: 0.2144 - val_accuracy: 0.9227\n",
            "Epoch 9/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.9223 - val_loss: 0.2106 - val_accuracy: 0.9216\n",
            "Epoch 10/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2229 - accuracy: 0.9234 - val_loss: 0.2067 - val_accuracy: 0.9221\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.2174 - accuracy: 0.9229\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9236\n",
            "Epoch 1/10\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 1.4066 - accuracy: 0.4888 - val_loss: 0.9944 - val_accuracy: 0.6382\n",
            "Epoch 2/10\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 0.8611 - accuracy: 0.6986 - val_loss: 0.7474 - val_accuracy: 0.7741\n",
            "Epoch 3/10\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.7888 - val_loss: 0.6190 - val_accuracy: 0.8306\n",
            "Epoch 4/10\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.8362 - val_loss: 0.5339 - val_accuracy: 0.8646\n",
            "Epoch 5/10\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.8631 - val_loss: 0.4731 - val_accuracy: 0.8898\n",
            "Epoch 6/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.8827 - val_loss: 0.4273 - val_accuracy: 0.9046\n",
            "Epoch 7/10\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8910 - val_loss: 0.3922 - val_accuracy: 0.9123\n",
            "Epoch 8/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.8971 - val_loss: 0.3643 - val_accuracy: 0.9150\n",
            "Epoch 9/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.9031 - val_loss: 0.3424 - val_accuracy: 0.9194\n",
            "Epoch 10/10\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.9062 - val_loss: 0.3244 - val_accuracy: 0.9172\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.9089\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.9092\n",
            "Epoch 1/10\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 1.1782 - accuracy: 0.5533 - val_loss: 0.7580 - val_accuracy: 0.7566\n",
            "Epoch 2/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.8274 - val_loss: 0.4663 - val_accuracy: 0.8821\n",
            "Epoch 3/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8873 - val_loss: 0.3407 - val_accuracy: 0.9079\n",
            "Epoch 4/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.9073 - val_loss: 0.2796 - val_accuracy: 0.9139\n",
            "Epoch 5/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.9150 - val_loss: 0.2505 - val_accuracy: 0.9200\n",
            "Epoch 6/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.9187 - val_loss: 0.2323 - val_accuracy: 0.9200\n",
            "Epoch 7/10\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 0.2442 - accuracy: 0.9209 - val_loss: 0.2224 - val_accuracy: 0.9200\n",
            "Epoch 8/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.9213 - val_loss: 0.2161 - val_accuracy: 0.9205\n",
            "Epoch 9/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.9205 - val_loss: 0.2110 - val_accuracy: 0.9238\n",
            "Epoch 10/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2256 - accuracy: 0.9201 - val_loss: 0.2083 - val_accuracy: 0.9221\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.2190 - accuracy: 0.9233\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9256\n",
            "Epoch 1/10\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 1.3944 - accuracy: 0.5448 - val_loss: 1.0297 - val_accuracy: 0.6787\n",
            "Epoch 2/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.8925 - accuracy: 0.7273 - val_loss: 0.7886 - val_accuracy: 0.7659\n",
            "Epoch 3/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.7215 - accuracy: 0.7915 - val_loss: 0.6553 - val_accuracy: 0.8333\n",
            "Epoch 4/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.8365 - val_loss: 0.5642 - val_accuracy: 0.8684\n",
            "Epoch 5/10\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.8668 - val_loss: 0.4972 - val_accuracy: 0.8843\n",
            "Epoch 6/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.8817 - val_loss: 0.4462 - val_accuracy: 0.9002\n",
            "Epoch 7/10\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8921 - val_loss: 0.4066 - val_accuracy: 0.9057\n",
            "Epoch 8/10\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8990 - val_loss: 0.3754 - val_accuracy: 0.9112\n",
            "Epoch 9/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.9050 - val_loss: 0.3506 - val_accuracy: 0.9123\n",
            "Epoch 10/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.9077 - val_loss: 0.3304 - val_accuracy: 0.9139\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.3443 - accuracy: 0.9097\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.9107\n",
            "Epoch 1/10\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 1.3438 - accuracy: 0.5616 - val_loss: 0.7649 - val_accuracy: 0.8032\n",
            "Epoch 2/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.8429 - val_loss: 0.4574 - val_accuracy: 0.8953\n",
            "Epoch 3/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8979 - val_loss: 0.3350 - val_accuracy: 0.9090\n",
            "Epoch 4/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.9090 - val_loss: 0.2781 - val_accuracy: 0.9167\n",
            "Epoch 5/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.9150 - val_loss: 0.2513 - val_accuracy: 0.9139\n",
            "Epoch 6/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.9175 - val_loss: 0.2359 - val_accuracy: 0.9145\n",
            "Epoch 7/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.9201 - val_loss: 0.2270 - val_accuracy: 0.9167\n",
            "Epoch 8/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2381 - accuracy: 0.9191 - val_loss: 0.2212 - val_accuracy: 0.9178\n",
            "Epoch 9/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.9205 - val_loss: 0.2155 - val_accuracy: 0.9189\n",
            "Epoch 10/10\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 0.2283 - accuracy: 0.9221 - val_loss: 0.2134 - val_accuracy: 0.9194\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.2229 - accuracy: 0.9213\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9228\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          activation  \\\n",
              "5  <keras.layers.activation.leaky_relu.LeakyReLU ...   \n",
              "3                                               relu   \n",
              "7  <keras.layers.activation.leaky_relu.LeakyReLU ...   \n",
              "1                                               relu   \n",
              "2                                               relu   \n",
              "\n",
              "                          loss optimizer  Точность на обучающем  \\\n",
              "5     categorical_crossentropy      adam               0.923347   \n",
              "3  kullback_leibler_divergence      adam               0.922908   \n",
              "7  kullback_leibler_divergence      adam               0.921263   \n",
              "1     categorical_crossentropy      adam               0.921592   \n",
              "2  kullback_leibler_divergence       SGD               0.911284   \n",
              "\n",
              "   Точность на тестовом  \n",
              "5              0.925646  \n",
              "3              0.923642  \n",
              "7              0.922752  \n",
              "1              0.921416  \n",
              "2              0.910953  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6499de69-ec25-442e-8933-bcc775067a50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>activation</th>\n",
              "      <th>loss</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>Точность на обучающем</th>\n",
              "      <th>Точность на тестовом</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;keras.layers.activation.leaky_relu.LeakyReLU ...</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.923347</td>\n",
              "      <td>0.925646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>relu</td>\n",
              "      <td>kullback_leibler_divergence</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.922908</td>\n",
              "      <td>0.923642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;keras.layers.activation.leaky_relu.LeakyReLU ...</td>\n",
              "      <td>kullback_leibler_divergence</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.921263</td>\n",
              "      <td>0.922752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>relu</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.921592</td>\n",
              "      <td>0.921416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>relu</td>\n",
              "      <td>kullback_leibler_divergence</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.911284</td>\n",
              "      <td>0.910953</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6499de69-ec25-442e-8933-bcc775067a50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6499de69-ec25-442e-8933-bcc775067a50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6499de69-ec25-442e-8933-bcc775067a50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "from itertools import product\n",
        "\n",
        "activation = [\"relu\", LeakyReLU()]\n",
        "loss = [\"categorical_crossentropy\", \"kullback_leibler_divergence\"]\n",
        "optimizer = [\"SGD\", \"adam\"]\n",
        "\n",
        "res = pd.DataFrame(columns=[\n",
        "    'activation', 'loss', 'optimizer',\n",
        "    'Точность на обучающем','Точность на тестовом' \n",
        "])\n",
        "\n",
        "for a, l, o in product(activation, loss, optimizer):  \n",
        "  model = Sequential()\n",
        "  model.add(Dense(units=28, input_dim = x_train.shape[1], activation = a))\n",
        "  model.add(Dense(7, activation = \"softmax\")) \n",
        "\n",
        "  model.compile(loss=l, optimizer=o,metrics = [\"accuracy\"])\n",
        "  model.fit(x_train, y_train, validation_split=0.2, epochs=10, batch_size=50, verbose=1)\n",
        "  res.loc[res.shape[0]] = [a,l,o,model.evaluate(x_train, y_train)[1],model.evaluate(x_test, y_test)[1]]\n",
        "\n",
        "res = res.sort_values('Точность на тестовом', ascending=False)\n",
        "res.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=280, input_dim = x_train.shape[1], activation = res.iloc[0]['activation']))\n",
        "model.add(Dense(7, activation = \"softmax\")) \n",
        "model.compile(loss=res.iloc[0]['loss'], optimizer=res.iloc[0]['optimizer'],metrics = [\"accuracy\"])\n",
        "model.fit(x_train, y_train, validation_split=0.2, epochs=10, batch_size=50, verbose=0)\n",
        "\n",
        "model.save('/content/model')\n",
        "\n",
        "print(f'Точность на тестовой выборке: {model.evaluate(x_test, y_test)[1]*100:.3f}%')\n",
        "print('\\nСтруктура модели:')\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vfe18-AyAZz",
        "outputId": "212897aa-3787-475e-feee-44a1f2ebf5c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as leaky_re_lu_18_layer_call_fn, leaky_re_lu_18_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141/141 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9288\n",
            "Точность на тестовой выборке: 92.876%\n",
            "\n",
            "Структура модели:\n",
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_143 (Dense)           (None, 280)               4760      \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 7)                 1967      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,727\n",
            "Trainable params: 6,727\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}